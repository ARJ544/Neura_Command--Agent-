{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af226e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from IPython.display import Image,Markdown,display_markdown ,display\n",
    "import getpass\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage,SystemMessage, ToolMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.tools import tool\n",
    "from tavily import TavilyClient\n",
    "from typing import Literal, Union, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88243c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
    "if \"TAVILY_API_KEY\" not in os.environ:\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your TAVILY API key: \")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a9fdf5",
   "metadata": {},
   "source": [
    "# TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892621ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "\n",
    "@tool\n",
    "def internet_search(\n",
    "    query: str,\n",
    "    max_results: int = 5,\n",
    "    start_date: str = None,\n",
    "    end_date: str = None,\n",
    "    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\",\n",
    "    include_raw_content: bool = False,\n",
    "):\n",
    "    \"\"\"Run a tavily web search\n",
    "    Args:\n",
    "        query: The search query. str\n",
    "        max_results: The maximum number of results to return. int\n",
    "        start_date: The start date for the search in YYYY-MM-DD format. str\n",
    "        end_date: The end date for the search in YYYY-MM-DD format. str\n",
    "        topic: The topic of the search. Can be \"general\", \"news\", \"finance\". str\n",
    "        include_raw_content: Whether to include the raw content of the results. boolean\n",
    "    \"\"\"\n",
    "    return tavily_client.search(\n",
    "        query,\n",
    "        max_results=max_results,\n",
    "        start_date= start_date,\n",
    "        end_date= end_date,\n",
    "        include_raw_content=include_raw_content,\n",
    "        topic=topic,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ae76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def extract_text_from_url(\n",
    "    urls: Union[List[str], str],\n",
    "    extract_depth: Literal[\"basic\", \"advanced\"] = \"advanced\",\n",
    "    format: Literal[\"markdown\", \"text\"] = \"markdown\",\n",
    "):\n",
    "    \"\"\"Extract text from a given URL using Tavily.\n",
    "    Args:\n",
    "        urls: The URL/urls to extract text from. list[str] or str\n",
    "        extract_depth: The depth of extraction. Can be \"basic\" or \"advanced\". str\n",
    "        format: type of format to extract. Can be \"markdown\" or \"text\". str\n",
    "    \"\"\"\n",
    "    return tavily_client.extract(\n",
    "        urls,\n",
    "        extract_depth=extract_depth,\n",
    "        format=format,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190563a0",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ff1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    \n",
    ")\n",
    "tools = [internet_search, extract_text_from_url]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "llmwithtools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc9e8d",
   "metadata": {},
   "source": [
    "# NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78fe9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = SystemMessage(content=\n",
    "    \"You are a helpful Agentic AI.Currently You have access to these tools \"\n",
    "    \"[internet_search, extract_text_from_url]. Use them as per need. \"\n",
    "    \"also you know which tool to use when.\\n\\n\"\n",
    "    \n",
    "    \"Citation Rules (Apply ONLY when using internet_search or extract_text_from_url):\\n\"\n",
    "    \"1. Every factual statement obtained from these two tools must include a \"\n",
    "    \"citation number like this: [1], [2], etc.\\n\"\n",
    "    \"2. At the END of your response, include a 'Sources:' section.\\n\"\n",
    "    \"3. In that section, list each cited source using this exact format:\\n\"\n",
    "    \"      [1] <URL>\\n\"\n",
    "    \"      [2] <URL>\\n\"\n",
    "    \"4. Each numbered citation must correspond to a URL from the tool results.\\n\"\n",
    "    \"5. If the response does NOT require or use these two tools, do NOT include any citations.\\n\\n\"\n",
    "    \n",
    "    \"These rules apply *only* to the tools internet_search and extract_text_from_url. \"\n",
    "    \"If other tools are added later, they are not affected by these citation rules unless specified.\\n\\n\"\n",
    "    \n",
    "    \"Be accurate, helpful, logical, always answer in markdown and follow citation rules strictly when required.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedcd1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_node(state: MessagesState):\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    if not any(msg.__class__.__name__ == \"SystemMessage\" for msg in messages):\n",
    "        messages.insert(0, system_msg)\n",
    "        \n",
    "    print(\"\\n\" + \"-----\"*10 + \" All Messages content \" + \"-----\"*10)\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, SystemMessage):\n",
    "            print(\"system msg =\", msg.content)\n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            print(\"human msg =\", msg.content)\n",
    "        # elif isinstance(msg, ToolMessage):\n",
    "        #     print(f\"tool msg = {msg.content}\")\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            print(\"assistant msg =\", msg.content)\n",
    "            print(\"usage_metadata = \", msg.usage_metadata)\n",
    "    print(\"-----\"*10 + \"End of All Messages content \" + \"-----\"*10 + \"\\n\")\n",
    "\n",
    "    # print(\"-----\"*50)\n",
    "    # print(f\"\\nAll Messages = {\"messages\"}\\n\")\n",
    "    print(\"-----\"*10 + \" Last Message content \" + \"-----\"*10)\n",
    "    print(f\"\\nLast message = {messages[-1]}\\n\")\n",
    "    print(\"-----\"*10 + \"End of Last Message content \" + \"-----\"*10)\n",
    "    response = llmwithtools.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c835a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tool_calls_node(state: MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    tool_outputs = []\n",
    "    print(\"\\n\" +\"-----\"*10 + \" Tool Calls to be executed \" + \"-----\"*10)\n",
    "    for tool_call in last_message.tool_calls:\n",
    "        \n",
    "        if tool_call[\"name\"] == \"internet_search\":\n",
    "            print(\"Invoking internet_search with args:\", tool_call[\"args\"])\n",
    "            result = internet_search.invoke(tool_call[\"args\"])\n",
    "            tool_outputs.append(ToolMessage(tool_call_id=tool_call['id'], content=str(result)))\n",
    "            \n",
    "        elif tool_call[\"name\"] == \"extract_text_from_url\":\n",
    "            print(\"Invoking extract_text_from_url with args:\", tool_call[\"args\"])\n",
    "            result = extract_text_from_url.invoke(tool_call[\"args\"])\n",
    "            tool_outputs.append(ToolMessage(tool_call_id=tool_call['id'], content=str(result)))\n",
    "    \n",
    "    print(\"-----\"*10 + \" End of Tool Calls execution \" + \"-----\"*10 + \"\\n\")\n",
    "            \n",
    "    return {\"messages\": tool_outputs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d2dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_call_tools(state: MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dc738f",
   "metadata": {},
   "source": [
    "# GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99716fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(\"llm_node\", call_llm_node)\n",
    "graph.add_node(\"execute_tool_calls_node\", execute_tool_calls_node)\n",
    "\n",
    "graph.add_edge(START,\"llm_node\")\n",
    "graph.add_conditional_edges(\n",
    "    \"llm_node\", \n",
    "    should_call_tools,\n",
    "    {\n",
    "        \"tools\": \"execute_tool_calls_node\",\n",
    "        \"end\": END,\n",
    "    }\n",
    ")\n",
    "graph.add_edge(\"execute_tool_calls_node\", \"llm_node\")\n",
    "\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "app = graph.compile(checkpointer=checkpointer)\n",
    "config = {\"configurable\": {\"thread_id\": \"ARJ\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80302ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the compiled app (CompiledStateGraph) which exposes the graph\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e7b1a",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4fe7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = {\"messages\": [HumanMessage(content=\"before bye writea python code of for loop of start pattern\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af11d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for event in app.astream_events(input1, config):\n",
    "    if event[\"event\"] == \"on_chat_model_stream\":\n",
    "        chunk = event[\"data\"][\"chunk\"].content\n",
    "        if chunk:\n",
    "            print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf982fc",
   "metadata": {},
   "source": [
    "# CHECKPOINT TESTING \n",
    "### To view last AI message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f2541",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_checkpoint = checkpointer.get(config)\n",
    "messages = latest_checkpoint[\"channel_values\"][\"messages\"]\n",
    "# print(messages)\n",
    "last_ai_msg = None\n",
    "for msg in reversed(messages):\n",
    "    if msg.__class__.__name__ == \"AIMessage\":\n",
    "        last_ai_msg = msg.content\n",
    "        break\n",
    "print(\"*\"*100)\n",
    "print(last_ai_msg)\n",
    "print(messages[0].__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac8a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_markdown(Markdown(last_ai_msg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
